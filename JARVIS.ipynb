{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehmanDadashov/JARVIS/blob/main/JARVIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Welcome to JARVIS.\n",
        "\n",
        "# The core of JARVIS is powered by Open Interpreter:\n",
        "\n",
        "for chunk in interpreter.chat(\"What's 34/24?\", stream=True, display=False):\n",
        "  print(chunk)\n",
        "\n",
        "# (This cell is for demonstration purposes. Do not run it until you've setup JARVIS below.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "I-16BvnEun7n",
        "outputId": "c6518d4a-dc43-4da3-cf32-e6b6bf5508bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'interpreter' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5ed77eb9858a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# The core of JARVIS is powered by Open Interpreter:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What's 34/24?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'interpreter' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install **(You must run ❗️`Runtime > Restart Session`❗️ after this)**"
      ],
      "metadata": {
        "id": "lE2GSFLJoOtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open-interpreter"
      ],
      "metadata": {
        "id": "iwI1Dhv7uzD-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36d892e7-52a8-42f0-a9d1-296c71d78a32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open-interpreter\n",
            "  Downloading open_interpreter-0.4.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting anthropic<0.38.0,>=0.37.1 (from open-interpreter)\n",
            "  Downloading anthropic-0.37.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting astor<0.9.0,>=0.8.1 (from open-interpreter)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting git-python<2.0.0,>=1.0.3 (from open-interpreter)\n",
            "  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
            "Collecting google-generativeai<0.8.0,>=0.7.1 (from open-interpreter)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting html2image<3.0.0.0,>=2.0.4.3 (from open-interpreter)\n",
            "  Downloading html2image-2.0.5-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting html2text<2025.0.0,>=2024.2.26 (from open-interpreter)\n",
            "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting inquirer<4.0.0,>=3.1.3 (from open-interpreter)\n",
            "  Downloading inquirer-3.4.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting ipykernel<7.0.0,>=6.26.0 (from open-interpreter)\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jupyter-client<9.0.0,>=8.6.0 (from open-interpreter)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting litellm<2.0.0,>=1.41.26 (from open-interpreter)\n",
            "  Downloading litellm-1.51.0-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting matplotlib<4.0.0,>=3.8.2 (from open-interpreter)\n",
            "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (3.8.1)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (4.3.6)\n",
            "Collecting psutil<6.0.0,>=5.9.6 (from open-interpreter)\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.4 in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (2.9.2)\n",
            "Requirement already satisfied: pyperclip<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (1.9.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (6.0.2)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.4.2 in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (13.9.3)\n",
            "Collecting selenium<5.0.0,>=4.24.0 (from open-interpreter)\n",
            "  Downloading selenium-4.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: send2trash<2.0.0,>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (1.8.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (75.1.0)\n",
            "Collecting shortuuid<2.0.0,>=1.0.13 (from open-interpreter)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: six<2.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (1.16.0)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from open-interpreter)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from open-interpreter)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tokentrim<0.2.0,>=0.1.13 (from open-interpreter)\n",
            "  Downloading tokentrim-0.1.13-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (0.10.2)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.10/dist-packages (from open-interpreter) (0.12.5)\n",
            "Collecting webdriver-manager<5.0.0,>=4.0.2 (from open-interpreter)\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting wget<4.0,>=3.2 (from open-interpreter)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting yaspin<4.0.0,>=3.0.2 (from open-interpreter)\n",
            "  Downloading yaspin-3.1.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic<0.38.0,>=0.37.1->open-interpreter)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic<0.38.0,>=0.37.1->open-interpreter)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.38.0,>=0.37.1->open-interpreter) (4.12.2)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (from git-python<2.0.0,>=1.0.3->open-interpreter) (3.1.43)\n",
            "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.1->open-interpreter)\n",
            "  Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.1->open-interpreter) (4.66.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (1.24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from html2image<3.0.0.0,>=2.0.4.3->open-interpreter) (2.32.3)\n",
            "Requirement already satisfied: websocket-client==1.* in /usr/local/lib/python3.10/dist-packages (from html2image<3.0.0.0,>=2.0.4.3->open-interpreter) (1.8.0)\n",
            "Collecting blessed>=1.19.0 (from inquirer<4.0.0,>=3.1.3->open-interpreter)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting editor>=1.6.0 (from inquirer<4.0.0,>=3.1.3->open-interpreter)\n",
            "  Downloading editor-1.6.6-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting readchar>=4.2.0 (from inquirer<4.0.0,>=3.1.3->open-interpreter)\n",
            "  Downloading readchar-4.2.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting comm>=0.1.1 (from ipykernel<7.0.0,>=6.26.0->open-interpreter)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (1.6.6)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (7.34.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (24.1)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (6.3.3)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7.0.0,>=6.26.0->open-interpreter) (5.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<9.0.0,>=8.6.0->open-interpreter) (2.8.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (3.10.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm<2.0.0,>=1.41.26->open-interpreter) (4.23.0)\n",
            "Collecting openai>=1.52.0 (from litellm<2.0.0,>=1.41.26->open-interpreter)\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm<2.0.0,>=1.41.26->open-interpreter)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.2->open-interpreter) (3.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->open-interpreter) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->open-interpreter) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.4->open-interpreter) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.4->open-interpreter) (2.23.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.4.2->open-interpreter) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.4.2->open-interpreter) (2.18.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.24.0->open-interpreter) (2.2.3)\n",
            "Collecting trio~=0.17 (from selenium<5.0.0,>=4.24.0->open-interpreter)\n",
            "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.24.0->open-interpreter)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium<5.0.0,>=4.24.0->open-interpreter) (2024.8.30)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.5->open-interpreter) (1.5.4)\n",
            "Collecting termcolor<2.4.0,>=2.2.0 (from yaspin<4.0.0,>=3.0.2->open-interpreter)\n",
            "  Downloading termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (1.2.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<4.0.0,>=3.1.3->open-interpreter) (0.2.13)\n",
            "Collecting runs (from editor>=1.6.0->inquirer<4.0.0,>=3.1.3->open-interpreter)\n",
            "  Downloading runs-1.2.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xmod (from editor>=1.6.0->inquirer<4.0.0,>=3.1.3->open-interpreter)\n",
            "  Downloading xmod-1.8.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (1.65.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (4.9)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic<0.38.0,>=0.37.1->open-interpreter)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<0.38.0,>=0.37.1->open-interpreter)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.41.26->open-interpreter) (3.20.2)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.41.26->open-interpreter) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.41.26->open-interpreter) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.41.26->open-interpreter) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.41.26->open-interpreter) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.41.26->open-interpreter) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.4.2->open-interpreter) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->html2image<3.0.0.0,>=2.0.4.3->open-interpreter) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (0.24.7)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium<5.0.0,>=4.24.0->open-interpreter)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.24.0->open-interpreter)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.24.0->open-interpreter)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.24.0->open-interpreter) (1.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython->git-python<2.0.0,>=1.0.3->open-interpreter) (4.0.11)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python<2.0.0,>=1.0.3->open-interpreter) (5.0.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (1.48.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.38.0,>=0.37.1->open-interpreter) (2024.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel<7.0.0,>=6.26.0->open-interpreter) (0.7.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.1->open-interpreter) (0.6.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->litellm<2.0.0,>=1.41.26->open-interpreter) (0.2.0)\n",
            "Downloading open_interpreter-0.4.3-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.4/255.4 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.37.1-py3-none-any.whl (945 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m946.0/946.0 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading html2image-2.0.5-py3-none-any.whl (28 kB)\n",
            "Downloading inquirer-3.4.0-py3-none-any.whl (18 kB)\n",
            "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.51.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokentrim-0.1.13-py3-none-any.whl (7.8 kB)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading yaspin-3.1.0-py3-none-any.whl (18 kB)\n",
            "Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading editor-1.6.6-py3-none-any.whl (4.0 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading readchar-4.2.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Downloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.7/481.7 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading runs-1.2.2-py3-none-any.whl (7.0 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading xmod-1.8.1-py3-none-any.whl (4.6 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: html2text, wget\n",
            "  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=7815a14f40324d2a93e8c71e727bdfdf0963aa335d2e59469598a783ffe79a27\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/96/6d/a7eba8f80d31cbd188a2787b81514d82fc5ae6943c44777659\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=d15543a7748873d0b5975382494bf6957a0ce39c2b90526a20d1b71d1ecd8f5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built html2text wget\n",
            "Installing collected packages: wget, sortedcontainers, xmod, termcolor, shortuuid, readchar, python-dotenv, psutil, outcome, jiter, jedi, html2text, h11, comm, blessed, astor, yaspin, wsproto, webdriver-manager, trio, tiktoken, starlette, runs, matplotlib, jupyter-client, httpcore, html2image, trio-websocket, tokentrim, ipykernel, httpx, git-python, editor, selenium, openai, inquirer, anthropic, litellm, google-ai-generativelanguage, google-generativeai, open-interpreter\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.5.0\n",
            "    Uninstalling termcolor-2.5.0:\n",
            "      Successfully uninstalled termcolor-2.5.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.10\n",
            "    Uninstalling google-ai-generativelanguage-0.6.10:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.10\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.8.3\n",
            "    Uninstalling google-generativeai-0.8.3:\n",
            "      Successfully uninstalled google-generativeai-0.8.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\n",
            "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anthropic-0.37.1 astor-0.8.1 blessed-1.20.0 comm-0.2.2 editor-1.6.6 git-python-1.0.3 google-ai-generativelanguage-0.6.6 google-generativeai-0.7.2 h11-0.14.0 html2image-2.0.5 html2text-2024.2.26 httpcore-1.0.6 httpx-0.27.2 inquirer-3.4.0 ipykernel-6.29.5 jedi-0.19.1 jiter-0.6.1 jupyter-client-8.6.3 litellm-1.51.0 matplotlib-3.9.2 open-interpreter-0.4.3 openai-1.52.2 outcome-1.3.0.post0 psutil-5.9.8 python-dotenv-1.0.1 readchar-4.2.0 runs-1.2.2 selenium-4.25.0 shortuuid-1.0.13 sortedcontainers-2.4.0 starlette-0.37.2 termcolor-2.3.0 tiktoken-0.7.0 tokentrim-0.1.13 trio-0.27.0 trio-websocket-0.11.1 webdriver-manager-4.0.2 wget-3.2 wsproto-1.2.0 xmod-1.8.1 yaspin-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "psutil"
                ]
              },
              "id": "9b43ee704c8c4f61bac5e6a586814018"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!pip install gradio==3.50 -q\n",
        "!pip install elevenlabs -q"
      ],
      "metadata": {
        "id": "GIyJZlbVYob4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec4ed3d-edcf-4480-997c-50c7715f0364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set your API Keys"
      ],
      "metadata": {
        "id": "yBlPE7TRVJWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eleven_labs_api_key = \"<your_api_key>\" # https://elevenlabs.io/speech-synthesis\n",
        "openai_api_key = \"<your_api_key>\" # https://platform.openai.com/account/api-keys"
      ],
      "metadata": {
        "id": "LI_6uNbs_K9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "aeic06e-o5Wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Misc Imports"
      ],
      "metadata": {
        "id": "CjrhRX6fWkXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time"
      ],
      "metadata": {
        "id": "XbzTmzACWlyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Open Interpreter"
      ],
      "metadata": {
        "id": "T9KaJXLXQtYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from interpreter import interpreter\n",
        "\n",
        "interpreter.llm.api_key = openai_api_key\n",
        "interpreter.auto_run = True"
      ],
      "metadata": {
        "id": "gpNOy1sLQs0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Whisper"
      ],
      "metadata": {
        "id": "TQ9iTzMQYs9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "id": "YstqtPbGoWXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(audio):\n",
        "\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "\n",
        "    # decode the audio\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    return result.text"
      ],
      "metadata": {
        "id": "JtTvvQQPcOZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ElevenLabs"
      ],
      "metadata": {
        "id": "kf751XxlyOd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from elevenlabs import generate, play, set_api_key\n",
        "\n",
        "set_api_key(eleven_labs_api_key)"
      ],
      "metadata": {
        "id": "qRcI6nlx8Cun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def get_audio_length(audio_bytes):\n",
        "  # Create a BytesIO object from the byte array\n",
        "  byte_io = io.BytesIO(audio_bytes)\n",
        "\n",
        "  # Load the audio data with PyDub\n",
        "  audio = AudioSegment.from_mp3(byte_io)\n",
        "\n",
        "  # Get the length of the audio in milliseconds\n",
        "  length_ms = len(audio)\n",
        "\n",
        "  # Optionally convert to seconds\n",
        "  length_s = length_ms / 1000.0\n",
        "\n",
        "  return length_s"
      ],
      "metadata": {
        "id": "o78_YmQwEBvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speak(text):\n",
        "  speaking = True\n",
        "  audio = generate(\n",
        "      text=text,\n",
        "      voice=\"Daniel\"\n",
        "  )\n",
        "  play(audio, notebook=True)\n",
        "\n",
        "  audio_length = get_audio_length(audio)\n",
        "  time.sleep(audio_length)"
      ],
      "metadata": {
        "id": "Ru3Z4M_L_FCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "X93f9Q5E_Gd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title JARVIS\n",
        "# @markdown ### **Setup Instructions**\n",
        "# @markdown 1. Run this cell, then scroll down to use the interface (don't click the link, and **give the interface 60 seconds to load**).\n",
        "# @markdown 2. Press the `Record from Microphone` button.\n",
        "# @markdown 3. Allow access to your microphone, then speak your command.\n",
        "# @markdown 4. Stop the recording, then press `Submit`.\n",
        "# @markdown\n",
        "# @markdown\n",
        "# @markdown JARVIS will respond verbally + carry out your command.\n",
        "\n",
        "last_sentence = \"\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    chatbot = gr.Chatbot()\n",
        "    audio_input = gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
        "    btn = gr.Button(\"Submit\")\n",
        "\n",
        "    def transcribe(audio):\n",
        "      audio = whisper.load_audio(audio)\n",
        "      audio = whisper.pad_or_trim(audio)\n",
        "      mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "      _, probs = model.detect_language(mel)\n",
        "      options = whisper.DecodingOptions()\n",
        "      result = whisper.decode(model, mel, options)\n",
        "      return result.text\n",
        "\n",
        "    def add_user_message(audio, history):\n",
        "        user_message = transcribe(audio)\n",
        "        return history + [[user_message, None]]\n",
        "\n",
        "    def bot(history):\n",
        "        global last_sentence\n",
        "\n",
        "        user_message = history[-1][0]\n",
        "        history[-1][1] = \"\"\n",
        "        active_block_type = \"\"\n",
        "        language = \"\"\n",
        "        for chunk in interpreter.chat(user_message, stream=True, display=False):\n",
        "\n",
        "            # I built this before we build the flags, like \"start\": True and \"end\": True.\n",
        "            # See the streaming example above. You can use those \"start\" and \"end\" flags to\n",
        "            # start the code blocks, message blocks, etc. Here we track it manually and ignore the flags.\n",
        "\n",
        "            # You should use the flags though! I was just lazy. We should rebuild this soon.\n",
        "\n",
        "            # Message\n",
        "            if chunk[\"type\"] == \"message\" and \"content\" in chunk:\n",
        "              if active_block_type != \"message\":\n",
        "                active_block_type = \"message\"\n",
        "              history[-1][1] += chunk[\"content\"]\n",
        "\n",
        "              last_sentence += chunk[\"content\"]\n",
        "              if any([punct in last_sentence for punct in \".?!\\n\"]):\n",
        "                yield history\n",
        "                speak(last_sentence)\n",
        "                last_sentence = \"\"\n",
        "              else:\n",
        "                yield history\n",
        "\n",
        "            # Code\n",
        "            if chunk[\"type\"] == \"code\" and \"content\" in chunk:\n",
        "              if active_block_type != \"code\":\n",
        "                active_block_type = \"code\"\n",
        "                history[-1][1] += f\"\\n```{chunk['format']}\"\n",
        "              history[-1][1] += chunk[\"content\"]\n",
        "              yield history\n",
        "\n",
        "            # Output\n",
        "            if chunk[\"type\"] == \"confirmation\":\n",
        "              history[-1][1] += \"\\n```\\n\\n```text\\n\"\n",
        "              yield history\n",
        "            if chunk[\"type\"] == \"console\":\n",
        "              if chunk.get(\"format\") == \"output\":\n",
        "                if chunk[\"content\"] == \"KeyboardInterrupt\":\n",
        "                  break\n",
        "                history[-1][1] += chunk[\"content\"] + \"\\n\"\n",
        "                yield history\n",
        "              if chunk.get(\"format\") == \"active_line\" and chunk[\"content\"] == None:\n",
        "                # Active line will be none when we finish execution.\n",
        "                # You could also detect this with \"type\": \"console\", \"end\": True.\n",
        "                history[-1][1] = history[-1][1].strip()\n",
        "                history[-1][1] += \"\\n```\\n\"\n",
        "                yield history\n",
        "\n",
        "        if last_sentence:\n",
        "          speak(last_sentence)\n",
        "\n",
        "    btn.click(add_user_message, [audio_input, chatbot], [chatbot]).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "O-xIJaH949uv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Text-only JARVIS\n",
        "# @markdown Run this cell for a ChatGPT-like interface.\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "\n",
        "    def user(user_message, history):\n",
        "        return \"\", history + [[user_message, None]]\n",
        "\n",
        "    def bot(history):\n",
        "\n",
        "        user_message = history[-1][0]\n",
        "        history[-1][1] = \"\"\n",
        "        active_block_type = \"\"\n",
        "\n",
        "        for chunk in interpreter.chat(user_message, stream=True, display=False):\n",
        "\n",
        "            # Message\n",
        "            if chunk[\"type\"] == \"message\" and \"content\" in chunk:\n",
        "              if active_block_type != \"message\":\n",
        "                active_block_type = \"message\"\n",
        "              history[-1][1] += chunk[\"content\"]\n",
        "\n",
        "              last_sentence += chunk[\"content\"]\n",
        "              if any([punct in last_sentence for punct in \".?!\\n\"]):\n",
        "                yield history\n",
        "                speak(last_sentence)\n",
        "                last_sentence = \"\"\n",
        "              else:\n",
        "                yield history\n",
        "\n",
        "            # Code\n",
        "            if chunk[\"type\"] == \"code\" and \"content\" in chunk:\n",
        "              if active_block_type != \"code\":\n",
        "                active_block_type = \"code\"\n",
        "                history[-1][1] += f\"\\n```{chunk['format']}\"\n",
        "              history[-1][1] += chunk[\"content\"]\n",
        "              yield history\n",
        "\n",
        "            # Output\n",
        "            if chunk[\"type\"] == \"confirmation\":\n",
        "              history[-1][1] += \"\\n```\\n\\n```text\\n\"\n",
        "              yield history\n",
        "            if chunk[\"type\"] == \"console\":\n",
        "              if chunk.get(\"format\") == \"output\":\n",
        "                if chunk[\"content\"] == \"KeyboardInterrupt\":\n",
        "                  break\n",
        "                history[-1][1] += chunk[\"content\"] + \"\\n\"\n",
        "                yield history\n",
        "              if chunk.get(\"format\") == \"active_line\" and chunk[\"content\"] == None:\n",
        "                # Active line will be none when we finish execution.\n",
        "                # You could also detect this with \"type\": \"console\", \"end\": True.\n",
        "                history[-1][1] = history[-1][1].strip()\n",
        "                history[-1][1] += \"\\n```\\n\"\n",
        "                yield history\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "mL1LS3NTlTtv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lE2GSFLJoOtI",
        "yBlPE7TRVJWF",
        "aeic06e-o5Wh",
        "CjrhRX6fWkXL",
        "T9KaJXLXQtYJ",
        "TQ9iTzMQYs9u",
        "kf751XxlyOd9"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}